# This outputs multiple one-liners to save money / make it faster

title: "code one liners from natural language"
future-titles:
- "Get code snippet"
# Any language
- "Get snippet"
next-version: "get-code-snippet.prompt"
doc: "Get a bash one liner from natural langauge"
prompt: |+
    Language: clojure
    Task: map string/split
    3 examples:
    - (map #(str/split % #"\s+") ["a-b-c" "1-2-3"])
    - (map #(str % #" ") ["Hello" "World"])
    - (map #(apply str (reverse %)) (re-seq #"[^ ]+" "hi there"))
    ###
    Language: ruby
    Task: extract values of a hash map to a list
    3 examples:
    - s = "abcdefg" s.reverse
    - gets.chomp.reverse
    - [:a, :b, :c].join('').reverse
    ###
    Language: haskell
    Task: Multiple Each Item in a List by 2
    2 examples:
    - map (*2) [1..10]
    - map (*2) [1..5]
    ###
    Language: bash
    Task: Recursively remove all "node_modules" folders
    Code:
    find . -name "node_modules" -exec rm -rf '{}' +
    ###
    Language: Haskell
    Task: Apply a function to both bits of a tuple:
    Code:
    both :: (a -> b) -> (a, a) -> (b, b)
    both = join (***)
    ###
    Language: Python
    Task: Palindrome Python One-Liner
    Code: phrase.find(phrase[::-1])
    ###
    Language: <1>    
    Task: <2>
    Code:
engine: "davinci"
# 0.0 = /r/hadastroke
# 1.0 = /r/iamveryrandom
# Use 0.3-0.8
temperature: 0.8
max-tokens: 60
top-p: 1.0
# Not available yet: openai api completions.create --help
frequency-penalty: 0.5
# If I make presence-penalty 0 then it will get very terse
presence-penalty: 0.0
best-of: 1
stop-sequences:
# - "\n"
# - "\n\n"
- "###"
inject-start-text: yes
inject-restart-text: yes
show-probabilities: off
vars:
- "language"
- "task"
examples:
- "bash"
- "suspend laptop"
chomp-start: on
chomp-end: off
external: ""
conversation-mode: no
filter: no
# Keep stitching together until reaching this limit
# This allows a full response for answers which may need n*max-tokens to reach the stop-sequence.
stitch-max: 0
needs-work: no